{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "y6yghjzv4rrclzzu7p4w",
   "authorId": "168336173847",
   "authorName": "DAVID.RIDER@SERVICENOW.COM",
   "authorEmail": "david.rider@servicenow.com",
   "sessionId": "52222432-d4ef-4e4e-a1e0-ffdbf71cdc8d",
   "lastEditTime": 1749831235290
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- Welcome to Snowflake Notebooks!\n-- Try out a SQL cell to generate some data.\nSELECT 'FRIDAY' as SNOWDAY, 0.2 as CHANCE_OF_SNOW\nUNION ALL\nSELECT 'SATURDAY',0.5\nUNION ALL \nSELECT 'SUNDAY', 0.9;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\nmy_df = cell2.to_pandas()\n\n# Chart the data\nst.subheader(\"Chance of SNOW ‚ùÑÔ∏è\")\nst.line_chart(my_df, x='SNOWDAY', y='CHANCE_OF_SNOW')\n\n# Give it a go!\nst.subheader(\"Try it out yourself and show off your skills ü•á\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4653f611-7e3e-40f8-9919-87cb48b39792",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# 1. Add a risk category\ndef classify_risk(prob):\n    if prob < 0.3:\n        return 'Low'\n    elif prob < 0.7:\n        return 'Moderate'\n    else:\n        return 'High'\n\nmy_df['RISK_LEVEL'] = my_df['CHANCE_OF_SNOW'].apply(classify_risk)\n\n# 2. Estimate snow depth (e.g., inches of snow assuming linear relation)\n# Let's say max possible snow is 12 inches\nmy_df['EST_SNOW_DEPTH_INCHES'] = (my_df['CHANCE_OF_SNOW'] * 12).round(1)\n\n# 3. Predict likelihood of road closure\n# Assume: Road likely closed if snow depth > 6 inches and risk is high\nmy_df['ROAD_CLOSURE_LIKELY'] = np.where(\n    (my_df['EST_SNOW_DEPTH_INCHES'] > 6) & (my_df['RISK_LEVEL'] == 'High'),\n    True, False\n)\n\n# 4. Visualization\nplt.figure(figsize=(8, 4))\ncolors = {'Low': 'green', 'Moderate': 'orange', 'High': 'red'}\nbars = plt.bar(\n    my_df['SNOWDAY'], \n    my_df['EST_SNOW_DEPTH_INCHES'], \n    color=[colors[r] for r in my_df['RISK_LEVEL']]\n)\nplt.title('Estimated Snow Depth by Day')\nplt.xlabel('Day')\nplt.ylabel('Estimated Snow (inches)')\nplt.ylim(0, 12)\n\n# Annotate bars with snow depth\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.3, f\"{yval}‚Ä≥\", ha='center')\n\nplt.tight_layout()\nplt.show()\n\n# Final DataFrame\nmy_df\n",
   "execution_count": null
  }
 ]
}